{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe37N4ip3dFEE/F3ORSl7j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivorima/VideoTracking-LK_DenseOptFlow/blob/main/Tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TP de Tracking**\n",
        "Rima Mahmoudi, M2 VMI\n",
        "\n",
        "Ce document contient le code et le compte rendu.\n",
        "\n",
        "PS: Il y aura une vidéo comme output pour voir le résultat ainsi que les frames affichées avec matplotlib\n",
        "\n",
        "Lien du Notebook: https://colab.research.google.com/drive/1jX5ETrmzCd6i23C37yewgvjbw-dr9UCF?usp=sharing"
      ],
      "metadata": {
        "id": "mzMhVjdv2rQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lucas-Kanade Optical flow"
      ],
      "metadata": {
        "id": "pR7kCrGdvmwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "video_path = \"/content/traffic.mp4\"\n",
        "cap = cv.VideoCapture(video_path)\n",
        "\n",
        "# Parameters for ShiTomasi corner detection\n",
        "feature_params = dict(maxCorners=150,\n",
        "                      qualityLevel=0.03,\n",
        "                      minDistance=7,\n",
        "                      blockSize=7)\n",
        "\n",
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict(winSize=(15, 15),\n",
        "                 maxLevel=2,\n",
        "                 criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
        "\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (150, 3))\n",
        "\n",
        "# Take first frame and find corners in it\n",
        "ret, old_frame = cap.read()\n",
        "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
        "p0 = cv.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "\n",
        "# Create a mask image for drawing purposes\n",
        "mask = np.zeros_like(old_frame)\n",
        "\n",
        "# initializing video for better display\n",
        "fourcc = cv.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv.VideoWriter('optical_flow_output.mp4', fourcc, 20.0, (old_frame.shape[1], old_frame.shape[0]))\n",
        "\n",
        "\n",
        "while(1):\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "\n",
        "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # calculate optical flow\n",
        "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "    # Select good points\n",
        "    good_new = p1[st==1] if p1 is not None and st.any() else None\n",
        "    good_old = p0[st==1] if p1 is not None and st.any() else None\n",
        "\n",
        "    # draw the tracks\n",
        "    if good_new is not None:\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
        "            frame = cv.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "        img = cv.add(frame, mask)\n",
        "\n",
        "        out.write(img)\n",
        "\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "        # update the previous frame and previous points\n",
        "        old_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "    else:\n",
        "      print(\"None!!\")\n",
        "      break\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n",
        "# Close the video writer\n",
        "out.release()"
      ],
      "metadata": {
        "id": "88TdmXYtx0hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compte-Rendu sur l'Implémentation de la Méthode de Flux Optique de Lucas-Kanade avec OpenCV**\n",
        "\n",
        "La méthode de Lucas-Kanade repose sur l'hypothèse que le flux optique est essentiellement constant dans un petit voisinage de l'image.\n",
        "\n",
        "\n",
        "# **Étapes principales:**\n",
        "\n",
        "* **Détection des Points d'Intérêt :** On utilise Shi-Tomasi pour détecter les coins (corners) dans la première image (frame). Les coins trouvés sont marqués en tant que points d'intéret, car ils serviront de points de référence pour notre tracking.\n",
        "\n",
        "* **Calcul du Flux Optique :** On applique la méthode Lucas-Kanade pour suivre les points d'intérêt extraits à travers les images de la vidéo.\n",
        "\n",
        "# **Paramètres pour la Détection des Coins Shi-Tomasi (feature_params) :**\n",
        "\n",
        " * **maxCorners:** Le nombre maximal de coins à détecter. Un nombre plus élevé augmente les chances de détecter plusieurs points d'intérêt mais ils ne seront pas tous fiables. Une valeur plus faible renvoie les angles les plus pertinants.\n",
        " * **qualityLevel:** Un paramètre indiquant la qualité minimale des coins. Des valeurs plus élevées signifient des coins de meilleure qualité, mais ils seront moins nombreux.\n",
        " * **minDistance:** La distance euclidienne minimale entre les coins détectés. Cela évite de détecter des coins trop proches les uns des autres.\n",
        " * **blockSize:** La taille de la fenêtre de voisinage utilisée pour la détection des angles. Une dimension de bloc plus large rend la détection moins sensible au bruit et permet de détecter moins de coins, mais ils seront plus fiables.\n",
        "\n",
        "# **Paramètres pour la Méthode de Lucas-Kanade (lk_params) :**\n",
        " * **winSize:** La taille de la fenêtre de recherche. Des fenêtres plus grandes peuvent capturer des mouvements plus importants, mais peuvent être moins précises pour de petits mouvements. Les fenêtres plus petites sont plus sensibles au bruit et peuvent manquer des mouvements plus importants.\n",
        " * **maxLevel:** Le nombre de niveaux de la pyramide utilisés. La valeur 0 signifie qu'aucune couche supplémentaire n'est créée dans la pyramide d'images. Des valeurs plus élevées permettent de suivre des points sur des mouvements plus importants, mais nécessitent davantage de calculs.\n",
        " * **criteria:** Critères d'arrêt de l'algorithme de recherche."
      ],
      "metadata": {
        "id": "3wt7ya6N4Y9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense Optical Flow"
      ],
      "metadata": {
        "id": "Ooxt6nIXvvgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "video_path = \"/content/traffic.mp4\"\n",
        "cap = cv.VideoCapture(video_path)\n",
        "\n",
        "ret, frame1 = cap.read()\n",
        "prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
        "hsv = np.zeros_like(frame1)\n",
        "hsv[..., 1] = 255\n",
        "\n",
        "# Initialize video writer\n",
        "fourcc = cv.VideoWriter_fourcc(*'MP4V')\n",
        "out = cv.VideoWriter('dense_optical_flow_output.mp4', fourcc, 20.0, (frame1.shape[1], frame1.shape[0]))\n",
        "\n",
        "# Process a set number of frames\n",
        "while(1):\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        print('No frames grabbed!')\n",
        "        break\n",
        "\n",
        "    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    pyr_scale = 0.5\n",
        "    levels = 3\n",
        "    winsize = 15\n",
        "    iterations = 3\n",
        "    poly_n = 5\n",
        "    poly_sigma = 1.2\n",
        "\n",
        "    flow = cv.calcOpticalFlowFarneback(prvs, next, None, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, 0)\n",
        "    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
        "    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
        "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
        "\n",
        "    out.write(bgr)\n",
        "\n",
        "    # Display image using matplotlib\n",
        "    plt.imshow(cv.cvtColor(bgr, cv.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "    prvs = next\n",
        "\n",
        "cap.release()\n",
        "out.release()  # Close the video writer\n"
      ],
      "metadata": {
        "id": "CyUrQqO5952J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compte-Rendu sur l'Implémentation de la Méthode du Flux Optique Dense de Farneback avec OpenCV**\n",
        "\n",
        "Contrairement au Flux Optique de Lucas-Kanade, le Flux Optique Dense calcule le mouvement pour chaque pixel.\n",
        "\n",
        "# **Étapes Principales**\n",
        "\n",
        "* **Initialisation des Paramètres :** Conversion de la première image en niveaux de gris et initialisation d'une image HSV pour la visualisation du flux optique.\n",
        "* **Calcul du Flux Optique :** À chaque image, le script calcule le flux optique en utilisant l'algorithme de Farneback, qui est ensuite converti en magnitude et en angle pour la visualisation.\n",
        "\n",
        "# **Paramètres de la méthode de flux optique dense de Farneback**\n",
        "* **pyr_scale :** Ce paramètre définit le facteur de réduction d'échelle pour la construction de la pyramide des images. Une valeur élevée a pour conséquence la perte de certains mouvements légers, une valeur faible Conserve plus de détails.\n",
        "\n",
        "* **Levels :** Le nombre de niveaux dans la pyramide d'images, avec une valeur élevée on Capture les mouvements sur de plus grandes distances, ce qui est utile pour suivre des objets se déplaçant rapidement ou de longues séquences comme dans notre video de traffic.\n",
        "\n",
        "\n",
        "* **winsize :** avec une valeur élevée, nous augmentons la résistance au bruit et la capacité à capturer de grands mouvements, mais nous risquons d'atténuer les détails.\n",
        "\n",
        "* **iterations :** Le nombre d'itérations à chaque niveau de la pyramide. Une valeur élevée améliore la précision du calcul du flux optique, mais augmente considérablement le temps de calcul.\n",
        "\n",
        "* **poly_n :** La taille de la fenêtre de voisinage pour l'approximation polynomiale."
      ],
      "metadata": {
        "id": "M4abjxFM-mVP"
      }
    }
  ]
}